{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import random\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.rcParams.update({\"text.usetex\": True, \"font.family\": \"serif\", \"font.serif\": [\"Computer Modern Roman\"]})\n",
    "\n",
    "from utils import global_monotonicity_violation, global_convexity_violation, peaking_detection\n",
    "from meta_feature import dataset_ids_CC18, anchor_list_denser, feature_num_CC18, class_num_CC18, learner_zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = [  Path.cwd() / '../dataset/LCDB11_ER_CC18_noFS_raw.hdf5',\n",
    "                Path.cwd() / '../dataset/LCDB11_ER_CC18_minmaxFS_raw.hdf5',\n",
    "                Path.cwd() / '../dataset/LCDB11_ER_CC18_standardFS_raw.hdf5']\n",
    "# file_paths = [  Path.cwd() / '../dataset/LCDB11_ER_265_noFS_raw_compress.hdf5',\n",
    "#                 Path.cwd() / '../dataset/LCDB11_ER_265_minmaxFS_raw_compress.hdf5',\n",
    "#                 Path.cwd() / '../dataset/LCDB11_ER_265_standardFS_raw_compress.hdf5']\n",
    "dataset_nofs, dataset_minmaxfs, dataset_standardfs = [h5py.File(fp, 'r')['error_rate'][...] for fp in file_paths]\n",
    "datasets = [dataset_nofs, dataset_minmaxfs, dataset_standardfs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monotonicity and Convexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for DATASET in datasets: \n",
    "    mono_matrix_y, mono_matrix_x = global_monotonicity_violation(DATASET, flat_filter = True)\n",
    "    conv_matrix, conv_h_matrix, conv_i_matrix, conv_j_matrix = global_convexity_violation(DATASET, flat_filter = True)\n",
    "    results.append({\n",
    "        \"mono_matrix_y\": mono_matrix_y,\n",
    "        \"mono_matrix_x\": mono_matrix_x,\n",
    "        \"conv_matrix\": conv_matrix,\n",
    "        \"conv_h_matrix\": conv_h_matrix,\n",
    "        \"conv_i_matrix\": conv_i_matrix,\n",
    "        \"conv_j_matrix\": conv_j_matrix,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Ratio: 2.89%\n",
      "Flat: 11.05%\n",
      "Monotone: 77.01%\n",
      "Convex: 77.45%\n",
      "Well-behaved: 74.51%\n",
      "-----------------------\n",
      "Missing Ratio: 0.38%\n",
      "Flat: 10.49%\n",
      "Monotone: 79.25%\n",
      "Convex: 80.71%\n",
      "Well-behaved: 76.95%\n",
      "-----------------------\n",
      "Missing Ratio: 8.33%\n",
      "Flat: 8.00%\n",
      "Monotone: 74.81%\n",
      "Convex: 75.71%\n",
      "Well-behaved: 72.89%\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "for result in results:\n",
    "    mono_matrix_y = result[\"mono_matrix_y\"]\n",
    "    conv_matrix = result[\"conv_matrix\"]\n",
    "    missing = (np.isnan(mono_matrix_y).sum() / mono_matrix_y.size) * 100\n",
    "    print(f\"Missing Ratio: {missing:.2f}%\") \n",
    "\n",
    "    flat_percentage_learner = (np.sum(mono_matrix_y == -1) / mono_matrix_y.size) * 100\n",
    "    print(f\"Flat: {flat_percentage_learner:.2f}%\")\n",
    "\n",
    "    mono_viola_percentage = (np.sum(mono_matrix_y == 0) / mono_matrix_y.size) * 100\n",
    "    print(f\"Monotone: {mono_viola_percentage:.2f}%\")\n",
    "    conv_viola_percentage = (np.sum(conv_matrix == 0) / conv_matrix.size) * 100\n",
    "    print(f\"Convex: {conv_viola_percentage:.2f}%\")\n",
    "\n",
    "    both_no_viola_percentage = (np.sum((conv_matrix == 0) & (mono_matrix_y == 0)) / mono_matrix_y.size) * 100\n",
    "    print(f\"Well-behaved: {both_no_viola_percentage:.2f}%\")\n",
    "    print(\"-----------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learner SVC_linear: Flat=0.00%, Monotone=95.83%, Well-behaved=94.44%\n",
      "Learner SVC_poly: Flat=19.44%, Monotone=80.56%, Well-behaved=79.17%\n",
      "Learner SVC_rbf: Flat=19.44%, Monotone=80.56%, Well-behaved=76.39%\n",
      "Learner SVC_sigmoid: Flat=11.11%, Monotone=30.56%, Well-behaved=27.78%\n",
      "Learner Decision Trees: Flat=2.78%, Monotone=97.22%, Well-behaved=97.22%\n",
      "Learner ExtraTrees: Flat=2.78%, Monotone=95.83%, Well-behaved=95.83%\n",
      "Learner LogisticRegression: Flat=2.78%, Monotone=97.22%, Well-behaved=93.06%\n",
      "Learner PassiveAggressive: Flat=1.39%, Monotone=93.06%, Well-behaved=93.06%\n",
      "Learner Perceptron: Flat=0.00%, Monotone=95.83%, Well-behaved=95.83%\n",
      "Learner RidgeClassifier: Flat=5.56%, Monotone=76.39%, Well-behaved=73.61%\n",
      "Learner SGDClassifier: Flat=0.00%, Monotone=97.22%, Well-behaved=97.22%\n",
      "Learner MLP: Flat=2.78%, Monotone=79.17%, Well-behaved=68.06%\n",
      "Learner LDA: Flat=2.78%, Monotone=54.17%, Well-behaved=48.61%\n",
      "Learner QDA: Flat=2.78%, Monotone=54.17%, Well-behaved=45.83%\n",
      "Learner BernoulliNB: Flat=19.44%, Monotone=70.83%, Well-behaved=65.28%\n",
      "Learner MultinomialNB: Flat=2.78%, Monotone=73.61%, Well-behaved=72.22%\n",
      "Learner ComplementNB: Flat=2.78%, Monotone=68.06%, Well-behaved=66.67%\n",
      "Learner GaussianNB: Flat=2.78%, Monotone=79.17%, Well-behaved=76.39%\n",
      "Learner KNN: Flat=13.89%, Monotone=84.72%, Well-behaved=83.33%\n",
      "Learner NearestCentroid: Flat=4.17%, Monotone=91.67%, Well-behaved=90.28%\n",
      "Learner ens.ExtraTrees: Flat=8.33%, Monotone=90.28%, Well-behaved=90.28%\n",
      "Learner ens.RandomForest: Flat=6.94%, Monotone=91.67%, Well-behaved=91.67%\n",
      "Learner ens.GradientBoosting: Flat=0.00%, Monotone=100.00%, Well-behaved=100.00%\n",
      "Learner DummyClassifier: Flat=73.61%, Monotone=23.61%, Well-behaved=20.83%\n",
      "\n",
      "\n",
      "Learner SVC_linear: Flat=5.56%, Monotone=93.06%, Well-behaved=93.06%\n",
      "Learner SVC_poly: Flat=2.78%, Monotone=97.22%, Well-behaved=95.83%\n",
      "Learner SVC_rbf: Flat=15.28%, Monotone=84.72%, Well-behaved=79.17%\n",
      "Learner SVC_sigmoid: Flat=11.11%, Monotone=31.94%, Well-behaved=30.56%\n",
      "Learner Decision Trees: Flat=0.00%, Monotone=98.61%, Well-behaved=98.61%\n",
      "Learner ExtraTrees: Flat=0.00%, Monotone=98.61%, Well-behaved=98.61%\n",
      "Learner LogisticRegression: Flat=13.89%, Monotone=86.11%, Well-behaved=86.11%\n",
      "Learner PassiveAggressive: Flat=1.39%, Monotone=98.61%, Well-behaved=98.61%\n",
      "Learner Perceptron: Flat=0.00%, Monotone=100.00%, Well-behaved=100.00%\n",
      "Learner RidgeClassifier: Flat=11.11%, Monotone=87.50%, Well-behaved=83.33%\n",
      "Learner SGDClassifier: Flat=0.00%, Monotone=100.00%, Well-behaved=100.00%\n",
      "Learner MLP: Flat=6.94%, Monotone=76.39%, Well-behaved=73.61%\n",
      "Learner LDA: Flat=2.78%, Monotone=54.17%, Well-behaved=48.61%\n",
      "Learner QDA: Flat=2.78%, Monotone=51.39%, Well-behaved=38.89%\n",
      "Learner BernoulliNB: Flat=13.89%, Monotone=72.22%, Well-behaved=69.44%\n",
      "Learner MultinomialNB: Flat=12.50%, Monotone=80.56%, Well-behaved=76.39%\n",
      "Learner ComplementNB: Flat=1.39%, Monotone=83.33%, Well-behaved=80.56%\n",
      "Learner GaussianNB: Flat=2.78%, Monotone=73.61%, Well-behaved=72.22%\n",
      "Learner KNN: Flat=11.11%, Monotone=87.50%, Well-behaved=86.11%\n",
      "Learner NearestCentroid: Flat=4.17%, Monotone=77.78%, Well-behaved=77.78%\n",
      "Learner ens.ExtraTrees: Flat=6.94%, Monotone=91.67%, Well-behaved=91.67%\n",
      "Learner ens.RandomForest: Flat=6.94%, Monotone=91.67%, Well-behaved=91.67%\n",
      "Learner ens.GradientBoosting: Flat=0.00%, Monotone=100.00%, Well-behaved=100.00%\n",
      "Learner DummyClassifier: Flat=73.61%, Monotone=23.61%, Well-behaved=20.83%\n",
      "\n",
      "\n",
      "Learner SVC_linear: Flat=1.39%, Monotone=98.61%, Well-behaved=97.22%\n",
      "Learner SVC_poly: Flat=6.94%, Monotone=93.06%, Well-behaved=88.89%\n",
      "Learner SVC_rbf: Flat=12.50%, Monotone=87.50%, Well-behaved=83.33%\n",
      "Learner SVC_sigmoid: Flat=6.94%, Monotone=51.39%, Well-behaved=48.61%\n",
      "Learner Decision Trees: Flat=0.00%, Monotone=98.61%, Well-behaved=98.61%\n",
      "Learner ExtraTrees: Flat=0.00%, Monotone=98.61%, Well-behaved=98.61%\n",
      "Learner LogisticRegression: Flat=4.17%, Monotone=95.83%, Well-behaved=93.06%\n",
      "Learner PassiveAggressive: Flat=0.00%, Monotone=98.61%, Well-behaved=98.61%\n",
      "Learner Perceptron: Flat=0.00%, Monotone=98.61%, Well-behaved=98.61%\n",
      "Learner RidgeClassifier: Flat=4.17%, Monotone=79.17%, Well-behaved=77.78%\n",
      "Learner SGDClassifier: Flat=0.00%, Monotone=97.22%, Well-behaved=95.83%\n",
      "Learner MLP: Flat=2.78%, Monotone=94.44%, Well-behaved=90.28%\n",
      "Learner LDA: Flat=1.39%, Monotone=54.17%, Well-behaved=47.22%\n",
      "Learner QDA: Flat=0.00%, Monotone=52.78%, Well-behaved=41.67%\n",
      "Learner BernoulliNB: Flat=6.94%, Monotone=90.28%, Well-behaved=87.50%\n",
      "Learner MultinomialNB: Flat=0.00%, Monotone=0.00%, Well-behaved=0.00%\n",
      "Learner ComplementNB: Flat=0.00%, Monotone=0.00%, Well-behaved=0.00%\n",
      "Learner GaussianNB: Flat=1.39%, Monotone=72.22%, Well-behaved=69.44%\n",
      "Learner KNN: Flat=12.50%, Monotone=81.94%, Well-behaved=81.94%\n",
      "Learner NearestCentroid: Flat=2.78%, Monotone=90.28%, Well-behaved=90.28%\n",
      "Learner ens.ExtraTrees: Flat=6.94%, Monotone=91.67%, Well-behaved=91.67%\n",
      "Learner ens.RandomForest: Flat=6.94%, Monotone=91.67%, Well-behaved=91.67%\n",
      "Learner ens.GradientBoosting: Flat=0.00%, Monotone=100.00%, Well-behaved=100.00%\n",
      "Learner DummyClassifier: Flat=73.61%, Monotone=23.61%, Well-behaved=20.83%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_learner_stats = []\n",
    "\n",
    "for result in results:\n",
    "    mono_matrix_y = result[\"mono_matrix_y\"]\n",
    "    conv_matrix = result[\"conv_matrix\"]\n",
    "    learner_stats = [{\"learner\": learner_zoo[i]} for i in range(24)]\n",
    "\n",
    "    for i in range(24):\n",
    "        mono_y_learner = mono_matrix_y[i, :]\n",
    "        conv_learner = conv_matrix[i, :]\n",
    "\n",
    "        missing_learner = (np.isnan(mono_y_learner).sum() / mono_y_learner.size) * 100\n",
    "        flat_percentage_learner = (np.sum(mono_y_learner == -1) / mono_y_learner.size) * 100\n",
    "        mono_viola_percentage_learner = (np.sum(mono_y_learner == 0) / mono_y_learner.size) * 100\n",
    "        conv_viola_percentage_learner = (np.sum(conv_learner == 0) / conv_learner.size) * 100\n",
    "        both_no_viola_percentage_learner = (np.sum((conv_learner == 0) & (mono_y_learner == 0)) / mono_y_learner.size) * 100\n",
    "\n",
    "        learner_stats[i].update({\n",
    "            \"missing\": missing_learner,\n",
    "            \"flat\": flat_percentage_learner,\n",
    "            \"monotone\": mono_viola_percentage_learner,\n",
    "            \"convex\": conv_viola_percentage_learner,\n",
    "            \"well_behaved\": both_no_viola_percentage_learner,\n",
    "        })\n",
    "\n",
    "    all_learner_stats.append({\n",
    "        \"learner_stats\": learner_stats\n",
    "    })\n",
    "\n",
    "for dataset_result in all_learner_stats:\n",
    "    for learner_stat in dataset_result[\"learner_stats\"]:\n",
    "        print(\n",
    "            f\"Learner {learner_stat['learner']}: \"\n",
    "            # f\"Missing={learner_stat['missing']:.2f}%, \"\n",
    "            f\"Flat={learner_stat['flat']:.2f}%, \"\n",
    "            f\"Monotone={learner_stat['monotone']:.2f}%, \"\n",
    "            # f\"Convex={learner_stat['convex']:.2f}%, \"\n",
    "            f\"Well-behaved={learner_stat['well_behaved']:.2f}%\"\n",
    "        )\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\\begin{sidewaystable}\n",
      "\\caption{Statistics for LCDB 1.1}\n",
      "\\label{tab:learner_stats}\n",
      "\\begin{tabular*}{\\textheight}{@{\\extracolsep\\fill}lcccccccccccccccccc}\n",
      "\\toprule%\n",
      "\\multirow{2}{*}{Shapes/Database} & \\multicolumn{3}{@{}c@{}}{LCDB 1.1 CC-18 noFS}& \\multicolumn{3}{@{}c@{}}{LCDB 1.1 CC-18 minmaxFS} & \\multicolumn{3}{@{}c@{}}{LCDB 1.1 CC-18 standardFS} \n",
      "\\\\\n",
      "\\cmidrule{2-4}\\cmidrule{5-7}\\cmidrule{8-10}\n",
      " & Flat & Monotone & Mono \\& Conv & Flat & Monotone & Mono \\& Conv & Flat & Monotone & Mono \\& Conv \\\\\n",
      "\\midrule\n",
      "SVC_linear & 0.00 & 95.83 & 94.44 & 5.56 & 93.06 & 93.06 & 1.39 & 98.61 & 97.22 \\\\\n",
      "SVC_poly & 19.44 & 80.56 & 79.17 & 2.78 & 97.22 & 95.83 & 6.94 & 93.06 & 88.89 \\\\\n",
      "SVC_rbf & 19.44 & 80.56 & 76.39 & 15.28 & 84.72 & 79.17 & 12.50 & 87.50 & 83.33 \\\\\n",
      "SVC_sigmoid & 11.11 & 30.56 & 27.78 & 11.11 & 31.94 & 30.56 & 6.94 & 51.39 & 48.61 \\\\\n",
      "Decision Trees & 2.78 & 97.22 & 97.22 & 0.00 & 98.61 & 98.61 & 0.00 & 98.61 & 98.61 \\\\\n",
      "ExtraTrees & 2.78 & 95.83 & 95.83 & 0.00 & 98.61 & 98.61 & 0.00 & 98.61 & 98.61 \\\\\n",
      "LogisticRegression & 2.78 & 97.22 & 93.06 & 13.89 & 86.11 & 86.11 & 4.17 & 95.83 & 93.06 \\\\\n",
      "PassiveAggressive & 1.39 & 93.06 & 93.06 & 1.39 & 98.61 & 98.61 & 0.00 & 98.61 & 98.61 \\\\\n",
      "Perceptron & 0.00 & 95.83 & 95.83 & 0.00 & 100.00 & 100.00 & 0.00 & 98.61 & 98.61 \\\\\n",
      "RidgeClassifier & 5.56 & 76.39 & 73.61 & 11.11 & 87.50 & 83.33 & 4.17 & 79.17 & 77.78 \\\\\n",
      "SGDClassifier & 0.00 & 97.22 & 97.22 & 0.00 & 100.00 & 100.00 & 0.00 & 97.22 & 95.83 \\\\\n",
      "MLP & 2.78 & 79.17 & 68.06 & 6.94 & 76.39 & 73.61 & 2.78 & 94.44 & 90.28 \\\\\n",
      "LDA & 2.78 & 54.17 & 48.61 & 2.78 & 54.17 & 48.61 & 1.39 & 54.17 & 47.22 \\\\\n",
      "QDA & 2.78 & 54.17 & 45.83 & 2.78 & 51.39 & 38.89 & 0.00 & 52.78 & 41.67 \\\\\n",
      "BernoulliNB & 19.44 & 70.83 & 65.28 & 13.89 & 72.22 & 69.44 & 6.94 & 90.28 & 87.50 \\\\\n",
      "MultinomialNB & 2.78 & 73.61 & 72.22 & 12.50 & 80.56 & 76.39 & 0.00 & 0.00 & 0.00 \\\\\n",
      "ComplementNB & 2.78 & 68.06 & 66.67 & 1.39 & 83.33 & 80.56 & 0.00 & 0.00 & 0.00 \\\\\n",
      "GaussianNB & 2.78 & 79.17 & 76.39 & 2.78 & 73.61 & 72.22 & 1.39 & 72.22 & 69.44 \\\\\n",
      "KNN & 13.89 & 84.72 & 83.33 & 11.11 & 87.50 & 86.11 & 12.50 & 81.94 & 81.94 \\\\\n",
      "NearestCentroid & 4.17 & 91.67 & 90.28 & 4.17 & 77.78 & 77.78 & 2.78 & 90.28 & 90.28 \\\\\n",
      "ens.ExtraTrees & 8.33 & 90.28 & 90.28 & 6.94 & 91.67 & 91.67 & 6.94 & 91.67 & 91.67 \\\\\n",
      "ens.RandomForest & 6.94 & 91.67 & 91.67 & 6.94 & 91.67 & 91.67 & 6.94 & 91.67 & 91.67 \\\\\n",
      "ens.GradientBoosting & 0.00 & 100.00 & 100.00 & 0.00 & 100.00 & 100.00 & 0.00 & 100.00 & 100.00 \\\\\n",
      "DummyClassifier & 73.61 & 23.61 & 20.83 & 73.61 & 23.61 & 20.83 & 73.61 & 23.61 & 20.83 \\\\\n",
      "\n",
      "\\bottomrule\n",
      "\\end{tabular*}\n",
      "\\end{sidewaystable}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "table_data = []\n",
    "for i in range(24):  \n",
    "    row = [learner_zoo[i]]  \n",
    "    for dataset_result in all_learner_stats:\n",
    "        learner_stat = dataset_result[\"learner_stats\"][i]\n",
    "        row.append(f\"{learner_stat['flat']:.2f}\")  # Flat\n",
    "        row.append(f\"{learner_stat['monotone']:.2f}\")  # Monotone\n",
    "        row.append(f\"{learner_stat['well_behaved']:.2f}\")  # Mono & Conv\n",
    "    table_data.append(row)\n",
    "\n",
    "\n",
    "latex_code = r\"\"\"\n",
    "\\begin{sidewaystable}\n",
    "\\caption{Statistics for LCDB 1.1}\n",
    "\\label{tab:learner_stats}\n",
    "\\begin{tabular*}{\\textheight}{@{\\extracolsep\\fill}lcccccccccccccccccc}\n",
    "\\toprule%\n",
    "\\multirow{2}{*}{Shapes/Database} & \\multicolumn{3}{@{}c@{}}{LCDB 1.1 CC-18 noFS}& \\multicolumn{3}{@{}c@{}}{LCDB 1.1 CC-18 minmaxFS} & \\multicolumn{3}{@{}c@{}}{LCDB 1.1 CC-18 standardFS} \n",
    "\\\\\n",
    "\\cmidrule{2-4}\\cmidrule{5-7}\\cmidrule{8-10}\n",
    " & Flat & Monotone & Mono \\& Conv & Flat & Monotone & Mono \\& Conv & Flat & Monotone & Mono \\& Conv \\\\\n",
    "\\midrule\n",
    "\"\"\"\n",
    "\n",
    "for row in table_data:\n",
    "    latex_code += \" & \".join(row) + r\" \\\\\" + \"\\n\"\n",
    "\n",
    "latex_code += r\"\"\"\n",
    "\\bottomrule\n",
    "\\end{tabular*}\n",
    "\\end{sidewaystable}\n",
    "\"\"\"\n",
    "\n",
    "print(latex_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learner SVC_linear: Missing=1.85%, Flat=0.00%, Monotone=95.83%, Convex=95.83%, Well-behaved=94.44%\n",
      "Learner SVC_poly: Missing=1.85%, Flat=19.44%, Monotone=80.56%, Convex=79.17%, Well-behaved=79.17%\n",
      "Learner SVC_rbf: Missing=1.85%, Flat=19.44%, Monotone=80.56%, Convex=76.39%, Well-behaved=76.39%\n",
      "Learner SVC_sigmoid: Missing=1.85%, Flat=11.11%, Monotone=30.56%, Convex=56.94%, Well-behaved=27.78%\n",
      "Learner Decision Trees: Missing=1.85%, Flat=2.78%, Monotone=97.22%, Convex=97.22%, Well-behaved=97.22%\n",
      "Learner ExtraTrees: Missing=1.85%, Flat=2.78%, Monotone=95.83%, Convex=97.22%, Well-behaved=95.83%\n",
      "Learner LogisticRegression: Missing=1.85%, Flat=2.78%, Monotone=97.22%, Convex=93.06%, Well-behaved=93.06%\n",
      "Learner PassiveAggressive: Missing=1.85%, Flat=1.39%, Monotone=93.06%, Convex=98.61%, Well-behaved=93.06%\n",
      "Learner Perceptron: Missing=1.85%, Flat=0.00%, Monotone=95.83%, Convex=98.61%, Well-behaved=95.83%\n",
      "Learner RidgeClassifier: Missing=1.85%, Flat=5.56%, Monotone=76.39%, Convex=73.61%, Well-behaved=73.61%\n",
      "Learner SGDClassifier: Missing=1.85%, Flat=0.00%, Monotone=97.22%, Convex=100.00%, Well-behaved=97.22%\n",
      "Learner MLP: Missing=1.85%, Flat=2.78%, Monotone=79.17%, Convex=70.83%, Well-behaved=68.06%\n",
      "Learner LDA: Missing=1.85%, Flat=2.78%, Monotone=54.17%, Convex=50.00%, Well-behaved=48.61%\n",
      "Learner QDA: Missing=1.85%, Flat=2.78%, Monotone=54.17%, Convex=58.33%, Well-behaved=45.83%\n",
      "Learner BernoulliNB: Missing=1.85%, Flat=19.44%, Monotone=70.83%, Convex=69.44%, Well-behaved=65.28%\n",
      "Learner MultinomialNB: Missing=1.85%, Flat=2.78%, Monotone=73.61%, Convex=73.61%, Well-behaved=72.22%\n",
      "Learner ComplementNB: Missing=1.85%, Flat=2.78%, Monotone=68.06%, Convex=72.22%, Well-behaved=66.67%\n",
      "Learner GaussianNB: Missing=1.85%, Flat=2.78%, Monotone=79.17%, Convex=83.33%, Well-behaved=76.39%\n",
      "Learner KNN: Missing=1.85%, Flat=13.89%, Monotone=84.72%, Convex=83.33%, Well-behaved=83.33%\n",
      "Learner NearestCentroid: Missing=1.85%, Flat=4.17%, Monotone=91.67%, Convex=93.06%, Well-behaved=90.28%\n",
      "Learner ens.ExtraTrees: Missing=1.85%, Flat=8.33%, Monotone=90.28%, Convex=91.67%, Well-behaved=90.28%\n",
      "Learner ens.RandomForest: Missing=1.85%, Flat=6.94%, Monotone=91.67%, Convex=93.06%, Well-behaved=91.67%\n",
      "Learner ens.GradientBoosting: Missing=1.85%, Flat=0.00%, Monotone=100.00%, Convex=100.00%, Well-behaved=100.00%\n",
      "Learner DummyClassifier: Missing=1.85%, Flat=73.61%, Monotone=23.61%, Convex=20.83%, Well-behaved=20.83%\n"
     ]
    }
   ],
   "source": [
    "learner_stats = [{\"learner\": learner_zoo[i]} for i in range(24)]\n",
    "for i in range(24):\n",
    "    mono_y_learner = mono_matrix_y[i, :]\n",
    "    conv_learner = conv_matrix[i, :]\n",
    "\n",
    "    missing_learner = (np.isnan(mono_matrix_y).sum() / mono_matrix_y.size) * 100\n",
    "    flat_percentage_learner = (np.sum(mono_y_learner == -1) / mono_y_learner.size) * 100\n",
    "    mono_viola_percentage_learner = (np.sum(mono_y_learner == 0) / mono_y_learner.size) * 100\n",
    "    conv_viola_percentage_learner = (np.sum(conv_learner == 0) / conv_learner.size) * 100\n",
    "    both_no_viola_percentage_learner = ( np.sum((conv_learner == 0) & (mono_y_learner == 0)) / mono_y_learner.size ) * 100\n",
    "    \n",
    "    # update\n",
    "    learner_stats[i].update({\n",
    "        \"missing\": missing_learner, \n",
    "        \"flat\": flat_percentage_learner,\n",
    "        \"monotone\": mono_viola_percentage_learner,\n",
    "        \"convex\": conv_viola_percentage_learner,\n",
    "        \"well_behaved\": both_no_viola_percentage_learner,\n",
    "    })\n",
    "\n",
    "for stat in learner_stats:\n",
    "    print(\n",
    "        f\"Learner {stat['learner']}: \"\n",
    "        f\"Missing={stat['missing']:.2f}%, \"\n",
    "        f\"Flat={stat['flat']:.2f}%, \"\n",
    "        f\"Monotone={stat['monotone']:.2f}%, \"\n",
    "        f\"Convex={stat['convex']:.2f}%, \"\n",
    "        f\"Well-behaved={stat['well_behaved']:.2f}%\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\\begin{table}[h!]\n",
      "\\caption{Statistics for LCDB 1.1 noFS.}\n",
      "\\label{tab:learner_stats}\n",
      "\\centering\n",
      "\\begin{tabular}{lccccc}\n",
      "\\hline\n",
      "Learner & Missing & Flat  & Monotone  & Convex  & Monotone \\& Convex  \\\\ \\hline\n",
      "SVC\\_linear & 1.85 & 0.00\\% & 95.83\\% & 95.83\\% & 94.44\\% \\\\ \n",
      "SVC\\_poly & 1.85 & 19.44\\% & 80.56\\% & 79.17\\% & 79.17\\% \\\\ \n",
      "SVC\\_rbf & 1.85 & 19.44\\% & 80.56\\% & 76.39\\% & 76.39\\% \\\\ \n",
      "SVC\\_sigmoid & 1.85 & 11.11\\% & 30.56\\% & 56.94\\% & 27.78\\% \\\\ \n",
      "Decision Trees & 1.85 & 2.78\\% & 97.22\\% & 97.22\\% & 97.22\\% \\\\ \n",
      "ExtraTrees & 1.85 & 2.78\\% & 95.83\\% & 97.22\\% & 95.83\\% \\\\ \n",
      "LogisticRegression & 1.85 & 2.78\\% & 97.22\\% & 93.06\\% & 93.06\\% \\\\ \n",
      "PassiveAggressive & 1.85 & 1.39\\% & 93.06\\% & 98.61\\% & 93.06\\% \\\\ \n",
      "Perceptron & 1.85 & 0.00\\% & 95.83\\% & 98.61\\% & 95.83\\% \\\\ \n",
      "RidgeClassifier & 1.85 & 5.56\\% & 76.39\\% & 73.61\\% & 73.61\\% \\\\ \n",
      "SGDClassifier & 1.85 & 0.00\\% & 97.22\\% & 100.00\\% & 97.22\\% \\\\ \n",
      "MLP & 1.85 & 2.78\\% & 79.17\\% & 70.83\\% & 68.06\\% \\\\ \n",
      "LDA & 1.85 & 2.78\\% & 54.17\\% & 50.00\\% & 48.61\\% \\\\ \n",
      "QDA & 1.85 & 2.78\\% & 54.17\\% & 58.33\\% & 45.83\\% \\\\ \n",
      "BernoulliNB & 1.85 & 19.44\\% & 70.83\\% & 69.44\\% & 65.28\\% \\\\ \n",
      "MultinomialNB & 1.85 & 2.78\\% & 73.61\\% & 73.61\\% & 72.22\\% \\\\ \n",
      "ComplementNB & 1.85 & 2.78\\% & 68.06\\% & 72.22\\% & 66.67\\% \\\\ \n",
      "GaussianNB & 1.85 & 2.78\\% & 79.17\\% & 83.33\\% & 76.39\\% \\\\ \n",
      "KNN & 1.85 & 13.89\\% & 84.72\\% & 83.33\\% & 83.33\\% \\\\ \n",
      "NearestCentroid & 1.85 & 4.17\\% & 91.67\\% & 93.06\\% & 90.28\\% \\\\ \n",
      "ens.ExtraTrees & 1.85 & 8.33\\% & 90.28\\% & 91.67\\% & 90.28\\% \\\\ \n",
      "ens.RandomForest & 1.85 & 6.94\\% & 91.67\\% & 93.06\\% & 91.67\\% \\\\ \n",
      "ens.GradientBoosting & 1.85 & 0.00\\% & 100.00\\% & 100.00\\% & 100.00\\% \\\\ \n",
      "DummyClassifier & 1.85 & 73.61\\% & 23.61\\% & 20.83\\% & 20.83\\% \\\\ \n",
      "\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "latex_table = r\"\"\"\n",
    "\\begin{table}[h!]\n",
    "\\caption{Statistics for LCDB 1.1 noFS.}\n",
    "\\label{tab:learner_stats}\n",
    "\\centering\n",
    "\\begin{tabular}{lccccc}\n",
    "\\hline\n",
    "Learner & Missing & Flat  & Monotone  & Convex  & Monotone \\& Convex  \\\\ \\hline\n",
    "\"\"\"\n",
    "for stat in learner_stats:\n",
    "    learner = str(stat[\"learner\"]).replace(\"_\", r\"\\_\")  # SVC_linear... need replace\n",
    "    missing = f\"{stat['missing']:.2f}\"\n",
    "    flat = f\"{stat['flat']:.2f}\"\n",
    "    monotone = f\"{stat['monotone']:.2f}\"\n",
    "    convex = f\"{stat['convex']:.2f}\"\n",
    "    both = f\"{stat['well_behaved']:.2f}\"\n",
    "    # write the number\n",
    "    latex_table += f\"{learner} & {missing} & {flat}\\% & {monotone}\\% & {convex}\\% & {both}\\% \\\\\\\\ \\n\"\n",
    "\n",
    "latex_table += r\"\"\"\n",
    "\\hline\n",
    "\\end{tabular}\n",
    "\\end{table}\n",
    "\"\"\"\n",
    "\n",
    "print(latex_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dipping and Peaking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:00<00:00, 78.10it/s]\n",
      "100%|██████████| 72/72 [01:31<00:00,  1.28s/it]\n",
      "100%|██████████| 72/72 [00:01<00:00, 62.88it/s]\n",
      "100%|██████████| 72/72 [01:49<00:00,  1.52s/it]\n",
      "100%|██████████| 72/72 [00:03<00:00, 19.76it/s]\n",
      "100%|██████████| 72/72 [01:46<00:00,  1.48s/it]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for DATASET in datasets: \n",
    "    mono_matrix_y, mono_matrix_x = global_monotonicity_violation(DATASET, flat_filter = True, dipping = True)\n",
    "    conv_matrix, conv_h_matrix, conv_i_matrix, conv_j_matrix = peaking_detection(DATASET, flat_filter = True)\n",
    "    results.append({\n",
    "        \"mono_matrix_y\": mono_matrix_y,\n",
    "        \"mono_matrix_x\": mono_matrix_x,\n",
    "        \"conv_matrix\": conv_matrix,\n",
    "        \"conv_h_matrix\": conv_h_matrix,\n",
    "        \"conv_i_matrix\": conv_i_matrix,\n",
    "        \"conv_j_matrix\": conv_j_matrix,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dipping: 6.42%\n",
      "Peaking: 6.02%\n",
      "-----------------------\n",
      "Dipping: 7.52%\n",
      "Peaking: 6.08%\n",
      "-----------------------\n",
      "Dipping: 5.79%\n",
      "Peaking: 5.32%\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "for result in results:\n",
    "    mono_matrix_y = result[\"mono_matrix_y\"]\n",
    "    conv_matrix = result[\"conv_matrix\"]\n",
    "\n",
    "    dipping_percentage = (np.sum(mono_matrix_y > 0) / mono_matrix_y.size) * 100\n",
    "    print(f\"Dipping: {dipping_percentage:.2f}%\")\n",
    "\n",
    "    peaking_percentage = (np.sum(conv_matrix > 0) / conv_matrix.size) * 100\n",
    "    print(f\"Peaking: {peaking_percentage:.2f}%\")\n",
    "\n",
    "    print(\"-----------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lcdb1-1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
