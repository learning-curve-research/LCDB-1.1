{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import itertools as it\n",
    "\n",
    "from meta_feature import dataset_ids_CC18, learner_zoo\n",
    "from utils import anchor_list_denser, successive_halving, get_datasets_and_learner_zoo_for_excluded_learners\n",
    "\n",
    "learner_zoo, learner_zoo_abbrv, dataset_nofs, dataset_minmaxfs, dataset_standardfs = get_datasets_and_learner_zoo_for_excluded_learners(excluded_learners=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     16,      32,      64,     128,     256,     512,    1024,\n",
       "          2048,    4096,    8192,   16384,   32768,   65536,  131072,\n",
       "        262144,  524288, 1048576, 2097152])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_schedule_for_budget_increase(b):\n",
    "    return anchor_list_denser[::b]\n",
    "\n",
    "get_schedule_for_budget_increase(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def successive_halving(learning_curves, budget, budget_increase, dropout_rate, active_mask=None, _history={}):\n",
    "    \n",
    "    # only on first call, activate all algorithms\n",
    "    if active_mask is None:\n",
    "        active_mask = np.ones(len(learning_curves))\n",
    "    \n",
    "    # append the current ensemble\n",
    "    indices_of_active_algorithms = [int(i) for i in np.where(active_mask)[0]]\n",
    "    _history[budget] = indices_of_active_algorithms\n",
    "    \n",
    "    # recursive cancellation\n",
    "    current_population_size = len(indices_of_active_algorithms)\n",
    "    if current_population_size <= 1 or budget >= learning_curves.shape[1]:\n",
    "        return _history\n",
    "    \n",
    "    # determine currently best\n",
    "    new_population_size = max(1, (current_population_size - dropout_rate) if dropout_rate >= 1 else int(np.round(current_population_size * (1 - dropout_rate))))\n",
    "    sorted_performances = np.argsort(learning_curves[:, budget])\n",
    "    survivors = [int(i) for i in sorted_performances if i in indices_of_active_algorithms][:new_population_size]\n",
    "    new_active_mask = np.array([i in survivors for i in range(len(learning_curves))])\n",
    "    \n",
    "    # recurse\n",
    "    return successive_halving(\n",
    "        learning_curves=learning_curves,\n",
    "        budget=budget + budget_increase,\n",
    "        budget_increase=budget_increase,\n",
    "        dropout_rate=dropout_rate,\n",
    "        active_mask=new_active_mask,\n",
    "        _history=_history\n",
    "    )\n",
    "\n",
    "def get_successive_halving_result_matrix(lc_db, start_budget, dropout_rate, budget_increase, max_k=10, num_outer_splits=5, regrets=True, verbose=False, quiet=False):\n",
    "\n",
    "    result_matrix = np.zeros((lc_db.shape[0], num_outer_splits, max_k))\n",
    "    for dataset_idx, lcs_on_dataset in enumerate(lc_db):\n",
    "        if verbose:\n",
    "            print(f\"Next dataset (index {dataset_idx}).\")\n",
    "        for outer_seed in range(num_outer_splits):\n",
    "            if verbose:\n",
    "                print(f\"Next test seed ({outer_seed}).\")\n",
    "            mean_val_curve = lcs_on_dataset[:, outer_seed, :, :, 1].mean(axis=1)\n",
    "\n",
    "            # cut down curve to the observable part\n",
    "            min_index = len(anchor_list_denser)\n",
    "            for i, alg_curve in enumerate(mean_val_curve):\n",
    "\n",
    "                # determine whether this learner has nan values and where these start\n",
    "                indices_with_nan = np.where(np.isnan(alg_curve))[0]\n",
    "                has_nan_values = len(indices_with_nan) > 0\n",
    "\n",
    "                if has_nan_values:\n",
    "                    first_index_with_nan = min(indices_with_nan)\n",
    "                    if first_index_with_nan == 0:  # starts with nan values\n",
    "                        if not quiet:\n",
    "                            print(f\"WARNING: Algorithm #{i} starts with nan entries in the mean curve for dataset idx {dataset_idx} on outer seed {outer_seed}. Changing nan scores to 2\")\n",
    "\n",
    "                        # In this case, treat all nans as 2-values (worst possible)\n",
    "                        mean_val_curve[i, np.isnan(mean_val_curve[i])] = 2\n",
    "                    \n",
    "                    else: # starts with values. In this case, we assume that nothing comes after first nan\n",
    "                        min_index = min(min_index, first_index_with_nan)\n",
    "\n",
    "            mean_val_curve = mean_val_curve[:, :min_index]\n",
    "\n",
    "            history = successive_halving(\n",
    "                learning_curves=mean_val_curve,\n",
    "                budget=start_budget,\n",
    "                budget_increase=budget_increase,\n",
    "                dropout_rate=dropout_rate,\n",
    "                _history={}\n",
    "            )\n",
    "            if verbose:\n",
    "                print(history)\n",
    "\n",
    "            # sanity check of result\n",
    "            prev_pop = None\n",
    "            for i, pop in history.items():\n",
    "                if prev_pop is not None:\n",
    "                    assert set(pop).issubset(set(prev_pop))\n",
    "                prev_pop = pop\n",
    "            \n",
    "            # determine whether best algorithm is selected\n",
    "            last_population = list(history.values())[-1]\n",
    "            if len(last_population) != 1:\n",
    "                print(\"warning, not converged to size 1. Taking  first element\")\n",
    "                last_population = last_population[:1]\n",
    "            if verbose:\n",
    "                print(f\"{last_population=}\")\n",
    "            \n",
    "            if regrets:\n",
    "                assert max_k == 1, \"If regrets is activated, make sure that max_k is 1\"\n",
    "                result_matrix[dataset_idx, outer_seed, 0] = mean_val_curve[last_population[0], -1] - np.min(mean_val_curve[:, -1])\n",
    "            else:\n",
    "                final_ranking = np.argsort(mean_val_curve[:, -1])\n",
    "                if verbose:\n",
    "                    print(f\"Final ranking at anchor {mean_val_curve.shape[1]} is {final_ranking} based on performances {np.round(mean_val_curve[:, -1], 3)}\")\n",
    "                for k_minus_one in range(max_k):\n",
    "                    result_matrix[dataset_idx, outer_seed, k_minus_one] = last_population[0] in final_ranking[:k_minus_one + 1]\n",
    "    return result_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#least_crossing_learners = ['SVC_sigmoid', 'PassiveAggressive', 'RidgeClassifier', 'BernoulliNB', 'ComplementNB']\n",
    "#most_crossing_learners = ['SVC_rbf', 'ExtraTrees', 'LDA', 'KNN', 'NearestCentroid']\n",
    "least_crossing_learners = ['SVC_sigmoid', 'Decision Tree', 'ExtraTree', 'ens.ExtraTrees', 'ens.RandomForest']\n",
    "most_crossing_learners = ['SVC_rbf', 'Perceptron', 'LDA', 'KNN', 'NearestCentroid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'SVC_sigmoid' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 61\u001b[39m\n\u001b[32m     58\u001b[39m     pbar.close()\n\u001b[32m     59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m pd.DataFrame(rows, columns=[\u001b[33m\"\u001b[39m\u001b[33mdataset_filter\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mlearner_filter\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mdropout_rate\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstart_budget\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mbudget_increase\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mkbest_inclusion_rates\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mregrets\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m df_results_least_crossing = \u001b[43mget_sh_ablation_results\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdatabase\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset_minmaxfs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[43m    \u001b[49m\u001b[43md_dropout_rates\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m    \u001b[49m\u001b[43md_start_budgets\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m15\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m    \u001b[49m\u001b[43md_budget_increases\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m    \u001b[49m\u001b[43mselected_learners\u001b[49m\u001b[43m=\u001b[49m\u001b[43mleast_crossing_learners\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_k\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\n\u001b[32m     68\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     70\u001b[39m df_results_most_crossing = get_sh_ablation_results(\n\u001b[32m     71\u001b[39m     database=dataset_minmaxfs,\n\u001b[32m     72\u001b[39m     d_dropout_rates=[\u001b[32m1\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m     76\u001b[39m     max_k=\u001b[32m4\u001b[39m\n\u001b[32m     77\u001b[39m )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mget_sh_ablation_results\u001b[39m\u001b[34m(database, max_k, d_dropout_rates, d_start_budgets, d_budget_increases, considered_datasets, selected_learners)\u001b[39m\n\u001b[32m     14\u001b[39m pbar = tqdm(total = \u001b[38;5;28mlen\u001b[39m(d_dropout_rates) * \u001b[38;5;28mlen\u001b[39m(d_start_budgets) * \u001b[38;5;28mlen\u001b[39m(d_budget_increases))\n\u001b[32m     16\u001b[39m dataset_slice = \u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;28;01mif\u001b[39;00m considered_datasets \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m [dataset_ids_CC18.index(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m considered_datasets]\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m learner_slice = \u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;28;01mif\u001b[39;00m selected_learners \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m [\u001b[43mlearner_zoo\u001b[49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43ml\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m selected_learners]\n\u001b[32m     18\u001b[39m _lc_db = database[dataset_slice, learner_slice]\n\u001b[32m     19\u001b[39m lc_db = _lc_db.reshape(\n\u001b[32m     20\u001b[39m     database.shape[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m considered_datasets \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(considered_datasets),\n\u001b[32m     21\u001b[39m     database.shape[\u001b[32m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m selected_learners \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(selected_learners),\n\u001b[32m   (...)\u001b[39m\u001b[32m     25\u001b[39m     database.shape[\u001b[32m5\u001b[39m]\n\u001b[32m     26\u001b[39m )\n",
      "\u001b[31mValueError\u001b[39m: 'SVC_sigmoid' is not in list"
     ]
    }
   ],
   "source": [
    "def get_sh_ablation_results(\n",
    "    database,\n",
    "    max_k=10,\n",
    "    d_dropout_rates = [0.5, 1, 2, 4],\n",
    "    d_start_budgets = [0, 1, 2, 3, 4, 7, 15],\n",
    "    d_budget_increases = [1, 2, 4, 8],\n",
    "    considered_datasets=None,\n",
    "    selected_learners=None\n",
    "    ):\n",
    "    \n",
    "    if selected_learners is not None:\n",
    "        max_k = min(max_k, len(selected_learners) - 1)\n",
    "\n",
    "    pbar = tqdm(total = len(d_dropout_rates) * len(d_start_budgets) * len(d_budget_increases))\n",
    "\n",
    "    dataset_slice = slice(None) if considered_datasets is None else [dataset_ids_CC18.index(i) for i in considered_datasets]\n",
    "    learner_slice = slice(None) if selected_learners is None else [learner_zoo.index(l) for l in selected_learners]\n",
    "    _lc_db = database[dataset_slice, learner_slice]\n",
    "    lc_db = _lc_db.reshape(\n",
    "        database.shape[0] if considered_datasets is None else len(considered_datasets),\n",
    "        database.shape[1] if selected_learners is None else len(selected_learners),\n",
    "        database.shape[2],\n",
    "        database.shape[3],\n",
    "        database.shape[4],\n",
    "        database.shape[5]\n",
    "    )\n",
    "\n",
    "    rows = []\n",
    "    for dropout_rate in d_dropout_rates:\n",
    "        for start_budget in d_start_budgets:\n",
    "            for budget_increase in d_budget_increases:\n",
    "\n",
    "                matrix_of_kbest_result_selection = get_successive_halving_result_matrix(\n",
    "                    lc_db=lc_db,\n",
    "                    dropout_rate=dropout_rate,\n",
    "                    budget_increase=budget_increase,\n",
    "                    max_k=max_k,\n",
    "                    start_budget=start_budget,\n",
    "                    verbose=False,\n",
    "                    quiet=True,\n",
    "                    regrets=False\n",
    "                )\n",
    "\n",
    "                # regrets\n",
    "                matrix_of_regrets = get_successive_halving_result_matrix(\n",
    "                    lc_db=lc_db,\n",
    "                    dropout_rate=dropout_rate,\n",
    "                    budget_increase=budget_increase,\n",
    "                    max_k=1,\n",
    "                    start_budget=start_budget,\n",
    "                    verbose=False,\n",
    "                    quiet=True,\n",
    "                    regrets=True\n",
    "                )\n",
    "                rows.append([considered_datasets, selected_learners, dropout_rate, start_budget, budget_increase, matrix_of_kbest_result_selection, matrix_of_regrets])\n",
    "\n",
    "                pbar.update(1)\n",
    "    pbar.close()\n",
    "    return pd.DataFrame(rows, columns=[\"dataset_filter\", \"learner_filter\", \"dropout_rate\", \"start_budget\", \"budget_increase\", \"kbest_inclusion_rates\", \"regrets\"])\n",
    "\n",
    "df_results_least_crossing = get_sh_ablation_results(\n",
    "    database=dataset_minmaxfs,\n",
    "    d_dropout_rates=[1],\n",
    "    d_start_budgets=[0, 1, 3, 7, 15],\n",
    "    d_budget_increases=[1, 2, 4, 8],\n",
    "    selected_learners=least_crossing_learners,\n",
    "    max_k=4\n",
    ")\n",
    "\n",
    "df_results_most_crossing = get_sh_ablation_results(\n",
    "    database=dataset_minmaxfs,\n",
    "    d_dropout_rates=[1],\n",
    "    d_start_budgets=[0, 1, 3, 7, 15],\n",
    "    d_budget_increases=[1, 2, 4, 8],\n",
    "    selected_learners=most_crossing_learners,\n",
    "    max_k=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_results_least_crossing' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdf_results_least_crossing\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'df_results_least_crossing' is not defined"
     ]
    }
   ],
   "source": [
    "df_results_least_crossing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_results_least_crossing' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df_results = pd.concat([\u001b[43mdf_results_least_crossing\u001b[49m, df_results_most_crossing])\n\u001b[32m      2\u001b[39m df_results\n",
      "\u001b[31mNameError\u001b[39m: name 'df_results_least_crossing' is not defined"
     ]
    }
   ],
   "source": [
    "df_results = pd.concat([df_results_least_crossing, df_results_most_crossing])\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_results_least_crossing' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 121\u001b[39m\n\u001b[32m    117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m fig, axs\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m start_budget, budget_increase \u001b[38;5;129;01min\u001b[39;00m it.product([\u001b[32m0\u001b[39m, \u001b[32m7\u001b[39m, \u001b[32m15\u001b[39m], [\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m4\u001b[39m, \u001b[32m8\u001b[39m]):\n\u001b[32m    120\u001b[39m     fig, axs = create_comparative_plot(\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m         \u001b[43mdf_results_least_crossing\u001b[49m[\n\u001b[32m    122\u001b[39m             (df_results_least_crossing[\u001b[33m\"\u001b[39m\u001b[33mstart_budget\u001b[39m\u001b[33m\"\u001b[39m] == start_budget) &\n\u001b[32m    123\u001b[39m             (df_results_least_crossing[\u001b[33m\"\u001b[39m\u001b[33mbudget_increase\u001b[39m\u001b[33m\"\u001b[39m] == budget_increase)\n\u001b[32m    124\u001b[39m         ],\n\u001b[32m    125\u001b[39m         df_results_most_crossing[\n\u001b[32m    126\u001b[39m             (df_results_most_crossing[\u001b[33m\"\u001b[39m\u001b[33mstart_budget\u001b[39m\u001b[33m\"\u001b[39m] == start_budget) &\n\u001b[32m    127\u001b[39m             (df_results_most_crossing[\u001b[33m\"\u001b[39m\u001b[33mbudget_increase\u001b[39m\u001b[33m\"\u001b[39m] == budget_increase)\n\u001b[32m    128\u001b[39m         ], \n\u001b[32m    129\u001b[39m         boxplot_kwargs_least = {\n\u001b[32m    130\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mpatch_artist\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    131\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mboxprops\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(color=\u001b[33m'\u001b[39m\u001b[33mblack\u001b[39m\u001b[33m'\u001b[39m, facecolor=\u001b[33m'\u001b[39m\u001b[33mC0\u001b[39m\u001b[33m'\u001b[39m, alpha=\u001b[32m0.5\u001b[39m),\n\u001b[32m    132\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mwidths\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m0.25\u001b[39m\n\u001b[32m    133\u001b[39m         },\n\u001b[32m    134\u001b[39m         boxplot_kwargs_most = {\n\u001b[32m    135\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mpatch_artist\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    136\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mboxprops\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(color=\u001b[33m'\u001b[39m\u001b[33mblack\u001b[39m\u001b[33m'\u001b[39m, facecolor=\u001b[33m'\u001b[39m\u001b[33mC1\u001b[39m\u001b[33m'\u001b[39m, alpha=\u001b[32m0.5\u001b[39m),\n\u001b[32m    137\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mwidths\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m0.25\u001b[39m\n\u001b[32m    138\u001b[39m         }\n\u001b[32m    139\u001b[39m     )\n\u001b[32m    140\u001b[39m     axs[\u001b[32m0\u001b[39m].set_xticks(\u001b[32m0.25\u001b[39m + np.arange(\u001b[32m1\u001b[39m, \u001b[32m5\u001b[39m))\n\u001b[32m    141\u001b[39m     axs[\u001b[32m0\u001b[39m].set_xticklabels([\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m=}\u001b[39;00m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, \u001b[32m5\u001b[39m)], rotation=\u001b[32m0\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'df_results_least_crossing' is not defined"
     ]
    }
   ],
   "source": [
    "def generate_top_k_selection_heatmaps(df_results, format=\".pdf\"):\n",
    "   \n",
    "    for _, row in df_results.iterrows():\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(20, 2))\n",
    "        sns.heatmap(row[\"kbest_inclusion_rates\"].mean(axis=1).T, cmap=\"Greens\", vmin=0, vmax=1, ax=ax)\n",
    "        ax.set_xticklabels(dataset_ids_CC18 if row[\"dataset_filter\"] is None else row[\"dataset_filter\"])\n",
    "        ax.set_xlabel(\"openml id\")\n",
    "        ax.set_yticklabels(range(1, row[\"kbest_inclusion_rates\"].shape[2] + 1))\n",
    "        ax.set_ylabel(\"k\")\n",
    "        ax.set_title(\n",
    "            f\"Probability that the selected algorithm is among the k best (across {row[\"kbest_inclusion_rates\"].shape[1]} outer splits) \"\n",
    "            f\"dropping out {row['dropout_rate']} in each round and increasing budget by {row['budget_increase']} starting at {row['start_budget']}\"\n",
    "        )\n",
    "        ax.grid(alpha=0.5)\n",
    "        #fig.savefig(f\"{folder}/winprobs_{mode}_{dropout_rate}_{budget_increase}_{start_budget}{format}\", bbox_inches=\"tight\")\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "def generate_regret_heatmaps(df_results, format=\".pdf\"):\n",
    "    for _, row in df_results.iterrows():\n",
    "        fig, ax = plt.subplots(figsize=(20, 1))\n",
    "        sns.heatmap(row[\"regrets\"].mean(axis=1).T, cmap=\"Reds\", vmin=0, vmax=0.5, ax=ax)\n",
    "        ax.set_xticklabels(dataset_ids_CC18 if row[\"dataset_filter\"] is None else row[\"dataset_filter\"])\n",
    "        ax.set_xlabel(\"openml id\")\n",
    "        ax.set_title(\n",
    "            f\"Avg. regret that the selected algorithm is among the k best (across {row[\"kbest_inclusion_rates\"].shape[1]} outer splits) \"\n",
    "            f\"dropping out {row['dropout_rate']} in each round and increasing budget by {row['budget_increase']} starting at {row['start_budget']}\"\n",
    "        )\n",
    "        ax.grid(alpha=0.5)\n",
    "        #fig.savefig(f\"{folder}/regrets_{mode}_{dropout_rate}_{budget_increase}_{start_budget}{format}\", bbox_inches=\"tight\")\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "def generate_top_k_selection_boxplots(df_results, offset=0, boxplot_kwargs={}, ax=None):\n",
    "\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(14, 5))\n",
    "    else:\n",
    "        fig = ax.get_figure()\n",
    "    \n",
    "    vals = []\n",
    "    labels = []\n",
    "    for i, row in df_results.iterrows():    \n",
    "        agg = row[\"kbest_inclusion_rates\"].mean(axis=1)\n",
    "        vals.extend(agg.T)\n",
    "        new_labels = [\n",
    "            f\"({row['start_budget']}, {row['budget_increase']}) - k ={k}\"\n",
    "            for k in range(1 ,5)\n",
    "        ]\n",
    "        labels.extend(new_labels)\n",
    "    assert len(vals) == len(labels)\n",
    "    boxplot_kwargs[\"positions\"] = offset + np.arange(1, 1 + len(vals))\n",
    "    ax.boxplot(vals, **boxplot_kwargs)\n",
    "    #ax.set_xticklabels(labels, rotation=90)\n",
    "    return fig, ax, {p: l for p, l in zip(boxplot_kwargs[\"positions\"], labels)}\n",
    "\n",
    "def generate_regret_boxplots(df_results, offset=0, boxplot_kwargs={}, ax=None):\n",
    "\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(14, 5))\n",
    "    else:\n",
    "        fig = ax.get_figure()\n",
    "    \n",
    "    vals = []\n",
    "    labels = []\n",
    "    for i, row in df_results.iterrows():    \n",
    "        agg = row[\"regrets\"].mean(axis=1).flatten()\n",
    "        vals.append(agg)\n",
    "        labels.append(f\"({row['start_budget']}, {row['budget_increase']})\")\n",
    "    assert len(vals) == len(labels)\n",
    "    boxplot_kwargs[\"positions\"] = offset + np.arange(1, 1 + len(vals))\n",
    "    ax.boxplot(vals, **boxplot_kwargs)\n",
    "    #ax.set_xticklabels(labels, rotation=90)\n",
    "    return fig, ax, {p: l for p, l in zip(boxplot_kwargs[\"positions\"], labels)}\n",
    "\n",
    "def create_comparative_plot(df_results_least_crossing, df_results_most_crossing, boxplot_kwargs_least, boxplot_kwargs_most):\n",
    "\n",
    "    # create figure\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(6, 3), gridspec_kw={\"width_ratios\": [3, 1]})\n",
    "\n",
    "    ax = axs[0]\n",
    "    _, _, labels_least_crossing = generate_top_k_selection_boxplots(\n",
    "        df_results_least_crossing.sort_values([\"budget_increase\", \"start_budget\"]),\n",
    "        boxplot_kwargs=boxplot_kwargs_least,\n",
    "        ax=ax\n",
    "    )\n",
    "    _, _, labels_most_crossing = generate_top_k_selection_boxplots(\n",
    "        df_results_most_crossing.sort_values([\"budget_increase\", \"start_budget\"]),\n",
    "        offset=0.35,\n",
    "        boxplot_kwargs=boxplot_kwargs_most,\n",
    "        ax=ax\n",
    "    )\n",
    "    df_labels = pd.concat([pd.Series(labels_least_crossing), pd.Series(labels_most_crossing)]).sort_index()\n",
    "    ax.set_xticks(df_labels.index)\n",
    "    ax.set_xticklabels(df_labels.sort_index(), rotation=80)\n",
    "    ax.set_xlim([0.8, max(df_labels.index) + 0.2])\n",
    "    ax.set_title(\"Probabilities to select a finally k-best algorithm\")\n",
    "\n",
    "    # now the regrets\n",
    "    ax = axs[1]\n",
    "    generate_regret_boxplots(df_results_least_crossing.sort_values([\"budget_increase\", \"start_budget\"]),\n",
    "        boxplot_kwargs=boxplot_kwargs_least,\n",
    "        ax=ax\n",
    "    )\n",
    "    generate_regret_boxplots(df_results_most_crossing.sort_values([\"budget_increase\", \"start_budget\"]),\n",
    "        boxplot_kwargs=boxplot_kwargs_most,\n",
    "        offset=0.35,\n",
    "        ax=ax\n",
    "    )\n",
    "    ax.set_xlim([0.8, 1.55])\n",
    "    ax.set_title(\"Regrets\")\n",
    "\n",
    "    for ax in axs:\n",
    "        ax.grid()\n",
    "    return fig, axs\n",
    "\n",
    "for start_budget, budget_increase in it.product([0, 7, 15], [1, 2, 4, 8]):\n",
    "    fig, axs = create_comparative_plot(\n",
    "        df_results_least_crossing[\n",
    "            (df_results_least_crossing[\"start_budget\"] == start_budget) &\n",
    "            (df_results_least_crossing[\"budget_increase\"] == budget_increase)\n",
    "        ],\n",
    "        df_results_most_crossing[\n",
    "            (df_results_most_crossing[\"start_budget\"] == start_budget) &\n",
    "            (df_results_most_crossing[\"budget_increase\"] == budget_increase)\n",
    "        ], \n",
    "        boxplot_kwargs_least = {\n",
    "            \"patch_artist\": True,\n",
    "            \"boxprops\": dict(color='black', facecolor='C0', alpha=0.5),\n",
    "            \"widths\": 0.25\n",
    "        },\n",
    "        boxplot_kwargs_most = {\n",
    "            \"patch_artist\": True,\n",
    "            \"boxprops\": dict(color='black', facecolor='C1', alpha=0.5),\n",
    "            \"widths\": 0.25\n",
    "        }\n",
    "    )\n",
    "    axs[0].set_xticks(0.25 + np.arange(1, 5))\n",
    "    axs[0].set_xticklabels([f\"{k=}\" for k in range(1, 5)], rotation=0)\n",
    "    axs[1].set_xticks([])\n",
    "    axs[1].set_yscale(\"log\")\n",
    "    fig.suptitle(f\"First anchor {anchor_list_denser[start_budget]}, Budget Increase per Round {np.round(100 * budget_increase / 8, 2)}%\")\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(f\"plots/successive_halving/{start_budget}_{budget_increase}.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lcdb11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
